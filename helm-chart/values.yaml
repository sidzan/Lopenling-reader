---
# Need to pass $BUILD_ID to this key when applying the helm chart in CI. 
# or 
# Set the commit hash for a particular buiild to deploy built image for that commit ID. (NOTE: This would work only if the image is built for that commit ID.)
releaseImageTag: cf66cfb 

# Setting this to true will make this a sandbox environment. It'll set the following:
# - nodeAffinity for the Monitor, Nodejs, Redis, Varnish, Web & Nginx pod to schedule opn node where preemptible=true
# - Set appropriate labels to Nginx pod
# - Requests images with the tag "sandbox-<releaseImageTag>"
sandbox: "false"
# Setting this to true setsup liveness, readiness & startup probes on the web pod. 
contentSandbox: "false"

# This value sets the name of the environment and it's associated objects. Some suggestions for the values are prod/dev/test
deployEnv: "dev" 

# Helps create services for nginx, nodeja, varnish and web pods with appropriate tags that help ArgoCD do blue green deployments.
previousServicesCount: "3"

# This is the project ID for images coming from gcr. Ther are two possible values for this currently development-205018 / production-deployment.
# Should pass ${PROJECT_ID} value to this when applying the helm chart in the CI pipeline.
projectID: development-205018 

# This is used in mongobackup & reindex-elasticsearch cron jobs.
slackWebhook: "https://hooks.slack.com/services/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"

web:
  containerImage: 
    repoLocation: gcr.io
    repoName: sefaria-web
  replicaCount: 7
  resources:
    web:   
      gunicornWorkerCount: 5
      gunicornThreadCount: 5
      request:
        memory: "10Gi"
        cpu: "1500m"
      limit:
        memory: "11Gi"
        cpu: "2000m"
    djangoLog:
      request:
        memory: "100Mi"
        cpu: "50m"
      limit:
        memory: "150Mi"
        cpu: "100m"

redis:
  resources:
    request:
      memory: "700Mi"
      cpu: "200m"
    limit:
      memory: "700Mi"
      cpu: "200m"

nodejs:
  containerImage: 
    repoLocation: gcr.io
    RepoName: sefaria-node
  replicaCount: 4
  resources:
    request:
      memory: "1Gi"
      cpu: "1000m"
    limit:
      memory: "1500Mi"
      cpu: "1500m"

varnish:
  containerImage:
    repoLocation: gcr.io
    RepoName: sefaria-varnish
    tag: v6
  replicaCount: 1
  resources:
    request:
      memory: "16Gi" # must be in megabibytes, because we pass it into the malloc definition
      cpu: "500m"
    limit:
      memory: "16Gi"
      cpu: "1000m"
  logging: {}
  tuning:
    # malloc should be ~75% of the memory request.
    malloc: "14440m"
    nuke_limit: "400"
    # Threading
    # http://book.varnish-software.com/4.0/chapters/Tuning.html#details-of-threading-parameters
    thread_pools: 2 # Default: 2
    thread_pool_max: 5000 # Default: 5000; should be a function of resources.request.memory
    thread_pool_min: 100 # Default: 100
    # Timers
    # http://book.varnish-software.com/4.0/chapters/Tuning.html#timers
    first_byte_timeout: 60 # Default 60s
    between_bytes_timeout: 60 # Default 60s

ingress:
  hosts: # You can set parth: serviceName: and port: for each host. By default they are set to '/*', 'nginx', '80' for each. Do note that changing this means you'll have to change the nginx service as well.
    - host: "{{ .Values.deployEnv }}.sefaria.org"
      path: /*
      serviceName: nginx
      port: 80
    - host: "{{ .Values.deployEnv }}.sefaria.org.il"
    - host: sefaria.org
    - host: sefaria.org.il
    - host: www.sefaria.org
    - host: www.sefaria.org.il
    - host: rollout.sefaria.org

nginx:
  containerImage: 
    repoLocation: gcr.io
    repoName: sefaria-asset
  replicaCount: 2
  resources:
    request:
      memory: "500Mi"
      cpu: "150m"
    limit:
      memory: "500Mi"
      cpu: "300m"

monitor:
  containerImage: 
    repoLocation: gcr.io
    repoName: sefaria-web
  replicaCount: 1
  resources:
    request:
      memory: "500Mi"
      cpu: "150m"
    limit:
      memory: "500Mi"
      cpu: "200m" 
...
